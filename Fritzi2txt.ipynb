{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#check all python modules\n","#pip list\n","\n","\n","# Workflow\n","# 1. Download VOD audio file only m4a (aac) > use Twitch Downloader > see also additional helper code below\n","# 2. DO_CONVERT_WAV: convert audio file from m4a to wav\n","# 3. DO_SPLIT_AUDIO: cut wav file into smaller files, if hardware has not enough power. 1h files are create for e.g. google colab > use T4 GPU for faster results\n","# 4. DO_TRANSCRIPT: Check which model size to use: tiny, small, medium, large\n","# 5. At the same time, an attempt is made to recognize the number of speakers and to assign them to what has been said in the audio track\n","#\n","# NOTE: as each audio part is transcribed independently, the labeled speakers differ from file to file!\n","# The code should automatically recognize whether CUDA is present. If not, everything is calculated on CPU (CPU is very slow ~1h for 5-10 Minutes of audio vs. 30-40 minutes for 1h audio with GPU)\n","\n","# Additional helper code\n","# convert from m4a to wav\n","# ffmpeg.exe -i \"NAME_of_FILE.m4a\" \"NAME_of_FILE.wav\"\n","\n","# Split into x second pieces\n","# ffmpeg.exe -i \"NAME_of_FILE.wav\" -f segment -segment_time 3600 -c copy \"NAME_of_FILE_part%03d.wav\""],"metadata":{"id":"SrbN0OK2vBej"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkRZW2EsRc5F"},"outputs":[],"source":["# Needed packages\n","# install for speaker recognition\n","!pip install pyannote.audio\n","\n","#install openai whisper offline use\n","!pip install openai-whisper\n","\n","# used for splitting wav\n","!pip install pydub"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"mynjsTVeXv7R"}},{"cell_type":"markdown","source":["Add google Drive as source for audiofiles"],"metadata":{"id":"jKKybfgVZCqh"}},{"cell_type":"code","source":["# mount google drive where audio files are stored\n","from google.colab import drive\n","#mount google drive for soundfiles\n","drive.mount('/content/google_drive', force_remount=False)\n"],"metadata":{"id":"9tUITSSKSZRz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"3J_3G1p_XxId"}},{"cell_type":"markdown","source":["**CONFIG**"],"metadata":{"id":"Rww365kDUSjh"}},{"cell_type":"code","source":["# need for read secrets token\n","from google.colab import userdata\n","\n","################################################################################\n","################################################################################\n","################################################################################\n","### Set here ###\n","#path to audio file\n","audio_path = '/content/google_drive/MyDrive/Fritzi/'\n","audio_file = '[12-19-24]_Panikfee_-_Fritzi im Chaos [Sektor]'\n","HF_TOKEN = userdata.get('HUGGING_FACE_TOKEN')\n","\n","audio_file_split_size = 60  #size in minutes per file\n","\n","\n","#generate combined TXT file and clean up some lines\n","kombiniert_einzeldateien_pfad = '/content/google_drive/MyDrive/Fritzi/Staffel2/'\n","kombinieren_ordner_pfad = '/content/google_drive/MyDrive/Fritzi/kombiniert/'\n","output_datei_name = '2024_12_21_Staffel2_kombiniert.txt'\n","\n","#Switch\n","MODELLSIZE = 'large'   #small, medium, large\n","DO_CONVERT_WAV = 1\n","DO_SPLIT_AUDIO = 1\n","DO_TRANSCRIPT = 1\n","################################################################################\n","################################################################################\n","################################################################################\n"],"metadata":{"id":"-TwiVs44hIkv","executionInfo":{"status":"ok","timestamp":1734695210519,"user_tz":-60,"elapsed":1044,"user":{"displayName":"Stina Brause","userId":"15764843027674506306"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"zQCf0WQjXreV"}},{"cell_type":"markdown","source":["Convert m4a to wav"],"metadata":{"id":"LEyWBjfzXnc6"}},{"cell_type":"code","source":["#convert m4a to wav/mp3\n","if DO_CONVERT_WAV == 1:\n","    from pydub import AudioSegment\n","    m4a_file = audio_path + audio_file + '.m4a'\n","    wav_filename = audio_path + audio_file + '.wav'\n","\n","    sound = AudioSegment.from_file(m4a_file, format='m4a')\n","    file_handle = sound.export(wav_filename, format='wav')\n","    print('done')\n","\n","    #print all files in directory\n","import os\n","audio_files_multi = os.listdir(audio_path)\n","print(audio_files_multi)"],"metadata":{"id":"3PwcBlteG5ls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    #print all files in directory\n","import os\n","audio_files_multi = os.listdir(audio_path)\n","print(audio_files_multi)"],"metadata":{"id":"3LlcBsdLLCT4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"yYje-t57X2XF"}},{"cell_type":"markdown","source":["Split Audio file in x Minute chunks"],"metadata":{"id":"JCu9So_ZUkHO"}},{"cell_type":"code","source":["### Splittet die Wav Datei in x Minuten Teile. Dies kann helfen, wenn die Hardware nicht soviel Performance hat\n","from pydub import AudioSegment\n","import math\n","def split_audio(file_path, segment_length=audio_file_split_size*60*1000):  # x minutes in milliseconds\n","\t# Load the audio file\n","\taudio = AudioSegment.from_file(file_path)\n","\n","\t# Get the total length of the audio file\n","\ttotal_length = len(audio)\n","\n","\t# Calculate the number of segments needed\n","\tnum_segments = math.ceil(total_length / segment_length)\n","\n","\t# Loop through and create each segment\n","\tfor i in range(num_segments):\n","\t\tstart_time = i * segment_length\n","\t\tend_time = min((i + 1) * segment_length, total_length)  # Ensure the last segment does not exceed total length\n","\t\tsegment = audio[start_time:end_time]\n","\n","\t\t# Generate the output file name\n","\t\toutput_file = f\"{file_path[:-4]}_part{i+1}.wav\"\n","\n","\t\t# Export the segment as an MP3 file\n","\t\tsegment.export(output_file, format=\"wav\")\n","\t\tprint(f\"Exported: {output_file}\")\n","\n","\n","if DO_SPLIT_AUDIO == 1:\n","\tsplit_audio(audio_path + audio_file + '.wav')"],"metadata":{"id":"Lr3XLUz6Gbyy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"46g4WNZOX7kN"}},{"cell_type":"markdown","source":["Recognise different speaker in audio file and do transcription"],"metadata":{"id":"Jq-UsfANqPil"}},{"cell_type":"code","source":["if DO_TRANSCRIPT == 1:\n","  import os\n","  import whisper\n","  import time\n","  import torch\n","  import torchaudio\n","  from pyannote.audio import Pipeline\n","  from pyannote.audio.pipelines.utils.hook import ProgressHook\n","  from pyannote.core import Segment\n","  import functools\n","\n","  # Funktion zum Formatieren der Zeit im Format hh:mm:ss\n","  def format_time(seconds):\n","      \"\"\"Konvertiere eine Zeit in Sekunden in das Format hh:mm:ss\"\"\"\n","      hours = int(seconds // 3600)\n","      minutes = int((seconds % 3600) // 60)\n","      seconds = int(seconds % 60)\n","      return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n","\n","  # Funktion zur Ermittlung der Anzahl der Parts\n","  def get_num_parts(audio_path, audio_file):\n","      \"\"\"Ermittelt die Anzahl der Part-Dateien im Verzeichnis\"\"\"\n","      parts = [f for f in os.listdir(audio_path) if f.startswith(audio_file) and f.endswith(\".wav\")]\n","      parts.sort()  # Optional, falls du die Dateien sortieren möchtest\n","      return parts\n","\n","  # Funktion zum Prüfen, ob alle Part-Dateien vorhanden sind\n","  def check_missing_parts(parts, num_parts):\n","      missing_parts = []\n","      for i in range(1, num_parts + 1):\n","          part_name = f\"{audio_file}_part{i}.wav\"\n","          if part_name not in parts:\n","              missing_parts.append(part_name)\n","      return missing_parts\n","\n","  # Tik: Startzeitpunkt\n","  print(\"Tik: Start der Ausführung\")\n","  start_time = time.time()\n","\n","  # CUDA-Speicher freigeben\n","  torch.cuda.empty_cache()\n","\n","  # Prüfe, ob CUDA verfügbar ist\n","  torch.cuda.is_available()\n","  DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","  # Höhere Genauigkeit, benötigt aber die richtige Hardware\n","  #if torch.cuda.is_available():\n","  #    torch.backends.cuda.matmul.allow_tf32 = True\n","  #    torch.backends.cudnn.allow_tf32 = True\n","\n","  # Umgebungsvariable für CUDA-Speicherverwaltung\n","  import os\n","  os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","\n","  # Lade das Whisper-Modell\n","  model = whisper.load_model(MODELLSIZE, device=DEVICE)  # 'small' Modell ohne fp16\n","\n","  # Lade die Sprecherdiarisierungs-Pipeline\n","  pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=HF_TOKEN)\n","  pipeline.to(torch.device(DEVICE))\n","\n","  # Ermittle die vorhandenen Teile\n","  parts = get_num_parts(audio_path, audio_file)\n","\n","  # Prüfe auf fehlende Parts\n","  missing_parts = check_missing_parts(parts, 10)  # Hier 10 anpassen, falls du eine andere maximale Anzahl von Parts erwartest\n","  if missing_parts:\n","      print(f\"Warnung: Die folgenden Part-Dateien fehlen: {', '.join(missing_parts)}\")\n","\n","  # Durchlaufe alle Parts und führe Transkription und Sprecherdiarisierung durch\n","  for part in parts:\n","      part_index = part.split(\"_\")[-1].replace(\".wav\", \"\")  # Extrahiere die Part-Nummer aus dem Dateinamen\n","\n","      print(f\"Verarbeite {part}...\")\n","\n","      # Lade die Audiodatei\n","      waveform, sample_rate = torchaudio.load(os.path.join(audio_path, part))\n","\n","      # Durchführen der Sprecherdiarisierung\n","      with ProgressHook() as hook:\n","          diarization = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate}, hook=hook)\n","\n","      # Transkription der Audiodatei mit Whisper\n","      result = model.transcribe(os.path.join(audio_path, part), language=\"de\", task=\"transcribe\", verbose=True, word_timestamps=True)\n","\n","      # Ausgabe in eine Textdatei exportieren\n","      output_file = os.path.join(audio_path, f\"{audio_file}_part{part_index}_mit_speakern.txt\")\n","\n","      # Öffnen der Datei im Schreibmodus\n","      with open(output_file, \"w\", encoding=\"utf-8\") as file:\n","          file.write(f\"Transkription Staffel 2 mit Sprechererkennung von {part}:\\n\")\n","\n","          # Durchlaufe die Segmente (jeder Abschnitt der Audiodatei)\n","          for segment in result[\"segments\"]:\n","              starting_time = format_time(segment['start'])\n","              ending_time = format_time(segment['end'])\n","              text = segment['text']\n","\n","              # Bestimme den Sprecher\n","              segment_time = Segment(segment['start'], segment['end'])\n","              speaker = None\n","              for turn, _, speaker_name in diarization.itertracks(yield_label=True):\n","                  if turn.start <= segment_time.end and turn.end >= segment_time.start:\n","                      speaker = speaker_name\n","                      break\n","\n","              # Wenn ein Sprecher erkannt wurde, nutze diesen, ansonsten setze 'Unbekannt'\n","              speaker_label = f\"Sprecher {speaker}\" if speaker else \"Unbekannt\"\n","\n","              # Schreibe Zeitstempel und Text mit Sprecherkennung\n","              file.write(f\"{starting_time} - {ending_time} - {speaker_label}: {text}\\n\")\n","\n","      print(f\"Die Transkription mit Sprechererkennung wurde erfolgreich in die Datei '{output_file}' exportiert.\")\n","\n","  # Berechne die Laufzeit\n","  end_time = time.time()\n","  elapsed_time = end_time - start_time\n","  hours = int(elapsed_time // 3600)\n","  minutes = int((elapsed_time % 3600) // 60)\n","  seconds = int(elapsed_time % 60)\n","\n","  # Ausgabe im Format hh:mm:ss\n","  print(f\"Laufzeit: {hours:02}:{minutes:02}:{seconds:02}\")\n","\n"],"metadata":{"id":"BosXmxC9HdqX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"76y14ERI04bP"}},{"cell_type":"markdown","source":["combine txt files to one file"],"metadata":{"id":"vsLqJJE53k_W"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"kltCsv4g3irK"}},{"cell_type":"code","source":["import os\n","from datetime import datetime\n","\n","# Definiere die Pfade\n","#kombinieren_ordner_pfad = '/Pfad/zum/kombinieren/Ordner'\n","#kombiniert_einzeldateien_pfad = '/Pfad/zum/Ordner/mit/Einzeldateien'\n","\n","# Name der neuen Datei, in der alle Inhalte zusammengeführt werden\n","neue_datei_pfad = os.path.join(kombinieren_ordner_pfad, output_datei_name)\n","\n","# Liste der .txt-Dateien im angegebenen Ordner\n","dateien = [datei_name for datei_name in os.listdir(kombiniert_einzeldateien_pfad) if datei_name.endswith('.txt')]\n","\n","# Funktion zum Extrahieren des Datums aus dem Dateinamen\n","def extrahiere_datum(datei_name):\n","    # Beispiel: \"[12-7-24] text.txt\" -> \"12-7-24\"\n","    datum_str = datei_name.split(']')[0][1:]  # Entferne die Klammern\n","    return datetime.strptime(datum_str, '%m-%d-%y')  # Wandelt in ein datetime-Objekt um\n","\n","# Sortiere die Dateien nach dem Datum im Dateinamen\n","dateien.sort(key=extrahiere_datum)\n","\n","# Öffne die neue Datei im Schreibmodus\n","with open(neue_datei_pfad, 'w', encoding='utf-8') as neue_datei:\n","    # Iteriere über alle sortierten Dateien\n","    for datei_name in dateien:\n","        datei_pfad = os.path.join(kombiniert_einzeldateien_pfad, datei_name)\n","\n","        # Gebe an, welche Datei gerade bearbeitet wird\n","        print(f\"Bearbeite Datei: {datei_name}\")\n","\n","        # Öffne die Datei und lese den Inhalt\n","        with open(datei_pfad, 'r', encoding='utf-8') as datei:\n","            inhalt = datei.read()\n","\n","            # Füge den Inhalt der neuen Datei hinzu\n","            neue_datei.write(inhalt + '\\n')  # '\\n' sorgt dafür, dass der Inhalt getrennt wird\n","\n","print(f\"Alle Inhalte wurden in {neue_datei_pfad} zusammengeführt.\")\n","\n"],"metadata":{"id":"lWJMkrefNDVt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","delete some special lines > see \"suchbegriff\""],"metadata":{"id":"oDJwm8Sr0euY"}},{"cell_type":"code","source":["# Dateipfad der .txt-Datei\n","#output_datei_name = '2024_12_20_Staffel2_kombiniert.txt'\n","\n","# Der Begriff, nach dem gesucht werden soll\n","suchbegriff = \"Untertitelung des ZDF, 2020\"\n","#suchbegriff = \"... Musik ...\"\n","#suchbegriff = \"Unbekannt:  ...\"\n","\n","\n","# Öffne die Datei und lies alle Zeilen\n","with open(audio_path +'kombiniert/'+ output_datei_name, 'r', encoding='utf-8') as datei:\n","    zeilen = datei.readlines()\n","\n","# Filtere alle Zeilen heraus, die den Suchbegriff enthalten\n","gefilterte_zeilen = [zeile for zeile in zeilen if suchbegriff not in zeile]\n","\n","# Berechne die Anzahl der gelöschten Zeilen (Zeilen, die den Suchbegriff enthalten)\n","anzahl_geloeschte_zeilen = len(zeilen) - len(gefilterte_zeilen)\n","\n","# Schreibe die gefilterten Zeilen zurück in die Datei\n","with open(audio_path +'kombiniert/'+ output_datei_name, 'w', encoding='utf-8') as datei:\n","    datei.writelines(gefilterte_zeilen)\n","\n","# Ausgabe der Anzahl der gelöschten Zeilen\n","print(f\"Die Zeilen mit dem Begriff '{suchbegriff}' wurden erfolgreich gelöscht.\")\n","print(f\"Anzahl der gelöschten Zeilen: {anzahl_geloeschte_zeilen}\")"],"metadata":{"id":"M86Xzlc9023D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","delete blank lines"],"metadata":{"id":"2kymb5va6Nhj"}},{"cell_type":"code","source":["import re\n","\n","# Dateipfad der .txt-Datei\n","#output_datei_name = '2024_12_19_Staffel2_kombiniert.txt'\n","\n","# Der Begriff, nach dem gesucht werden soll\n","suchbegriff = r\"^\\d{2}:\\d{2}:\\d{2} - \\d{2}:\\d{2}:\\d{2} - (Unbekannt|Sprecher SPEAKER_(0[0-9]|1[0-9]|20)):\\s*$\"\n","\n","\n","# Öffne die Datei und lese alle Zeilen\n","with open(audio_path + 'kombiniert/' + output_datei_name, 'r', encoding='utf-8') as datei:\n","    zeilen = datei.readlines()\n","\n","# Filtere alle Zeilen heraus, die einen bestimmten Sprecher (\"Unbekannt\" oder \"Sprecher SPEAKER_XX\") enthalten und keinen weiteren Text\n","gefilterte_zeilen = [\n","    zeile for zeile in zeilen\n","    if not re.match(suchbegriff, zeile)\n","]\n","\n","# Berechne die Anzahl der gelöschten Zeilen (Zeilen, die den Suchbegriff enthalten)\n","anzahl_geloeschte_zeilen = len(zeilen) - len(gefilterte_zeilen)\n","\n","# Schreibe die gefilterten Zeilen zurück in die Datei\n","with open(audio_path + 'kombiniert/' + output_datei_name, 'w', encoding='utf-8') as datei:\n","    datei.writelines(gefilterte_zeilen)\n","\n","# Ausgabe der Anzahl der gelöschten Zeilen\n","print(f\"Die Zeilen mit dem Begriff '{suchbegriff}' wurden erfolgreich gelöscht.\")\n","print(f\"Anzahl der gelöschten Zeilen: {anzahl_geloeschte_zeilen}\")\n"],"metadata":{"id":"zk02f8y8I58P"},"execution_count":null,"outputs":[]}]}